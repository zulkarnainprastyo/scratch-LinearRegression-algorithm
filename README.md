# Scratch Algorithm Machine Learning - Pacmann Project

## Step #1 - Select Machine Learning Algorithm
Search for algorithm references from valid sources. Examples of lecture notes/slides, papers, conferences, and books.
Lecture notes from CMU Statistics (https://www.stat.cmu.edu/~cshalizi/TALR/TALR.pdf).

## Step #2 - Create Algorithms from Scratch

To understand the learning components of the Linear Regression algorithm, I will refer to the provided source, "Linear Regression" Lecture notes from CMU Statistics (https://www.stat.cmu.edu/~cshalizi/TALR/TALR.pdf).

1. To for Fitting:
    * What is Optimized: Mean Squared Error (MSE) Cost Function
    * Objective of Optimization: Minimize the Cost Function
    * Parameters to Optimize: Slope (Weight) and Intercept (Bias)
    * Optimization Algorithm: Gradient Descent

2. To make predictions:
    * Prediction: Multiply Input Feature by Weight, Add Bias
    
    Here is the pseudocode for fitting the Linear Regression model:
    C:\ProjectAdvancedML\scratch-LinearRegression-algorithmML\scratch-LinearRegression-algorithm\pseudocode_fitting._linear_reegression_model.py

    Here is the pseudocode for making predictions with the trained Linear Regression model:
    C:\ProjectAdvancedML\scratch-LinearRegression-algorithmML\scratch-LinearRegression-algorithm\pseudocode_prediction.py

    Code Implementation:
    
    Here is the implementation of the Linear Regression Algorithm in a file named linear_regression.py:
    C:\ProjectAdvancedML\scratch-LinearRegression-algorithmML\scratch-LinearRegression-algorithm\linear_regression.py

## Step #3 - Analysis, Conclusion, and References

Applying the Scratch Code to Simple Data:

I can apply the code to simple data by creating input features X and corresponding target values y, then using the LinearRegression class to fit the model and make predictions.

## References:

* "Linear Regression" lecture notes from CMU Statistics by Cosma Rohilla Shalizi (https://www.stat.cmu.edu/~cshalizi/TALR/TALR.pdf)